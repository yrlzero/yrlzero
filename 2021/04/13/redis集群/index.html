<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yrlzero.gitee.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="一、主从复制1、概念 一个master可以拥有多个slave。 master的复制是异步非阻塞的。 客户端可以使用wait命令请求同步复制某些特定数据。 正常连接情况下，master通过命令流来保持对slave的数据更新。 master与slave之间得到连接断开，slave在尝试与master重连后，会尝试获取与master断开期间丢失的命令流 当断开期间的数据无法重新同步时，slave会请求全">
<meta property="og:type" content="article">
<meta property="og:title" content="redis-集群">
<meta property="og:url" content="http://yrlzero.gitee.io/2021/04/13/redis%E9%9B%86%E7%BE%A4/index.html">
<meta property="og:site_name" content="yrl&#39;s blog">
<meta property="og:description" content="一、主从复制1、概念 一个master可以拥有多个slave。 master的复制是异步非阻塞的。 客户端可以使用wait命令请求同步复制某些特定数据。 正常连接情况下，master通过命令流来保持对slave的数据更新。 master与slave之间得到连接断开，slave在尝试与master重连后，会尝试获取与master断开期间丢失的命令流 当断开期间的数据无法重新同步时，slave会请求全">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E5%89%8D%E5%8F%B0%E5%90%AF%E5%8A%A8redis-01.jpg">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E4%BB%8E%E8%8A%82%E7%82%B9%E8%BF%BD%E9%9A%8F%E4%B8%BB%E8%8A%82%E7%82%B9-%E4%BB%8E%E8%8A%82%E7%82%B9%E6%8E%A7%E5%88%B6%E5%8F%B0%E6%97%A5%E5%BF%97-03.jpg">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E4%BB%8E%E8%8A%82%E7%82%B9%E8%BF%BD%E9%9A%8F%E4%B8%BB%E8%8A%82%E7%82%B9-%E4%B8%BB%E8%8A%82%E7%82%B9%E6%8E%A7%E5%88%B6%E5%8F%B0%E6%97%A5%E5%BF%97-04.jpg">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E4%BB%8E%E8%8A%82%E7%82%B9%E7%9B%91%E6%8E%A7%E5%88%B0%E4%B8%BB%E8%8A%82%E7%82%B9%E5%AE%95%E6%9C%BA-05.jpg">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E4%BB%8E%E8%8A%82%E7%82%B9%E5%B0%86%E8%87%AA%E5%B7%B1%E5%8D%87%E7%BA%A7%E4%B8%BA%E4%B8%BB%E8%8A%82%E7%82%B9-06.jpg">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E4%BB%8E%E8%8A%82%E7%82%B9%E8%BF%BD%E9%9A%8F%E5%89%8D%E5%90%8E%E6%95%B0%E6%8D%AE%E5%8F%98%E5%8C%96-05.jpg">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/%E5%93%A8%E5%85%B5%E8%8A%82%E7%82%B9%E5%90%AF%E5%8A%A8-01.jpg">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/%E5%93%A8%E5%85%B5%E8%8A%82%E7%82%B9%E5%8F%91%E7%8E%B0%E4%B8%BB%E8%8A%82%E7%82%B9%E6%8C%82%E4%BA%86%E9%87%8D%E6%96%B0%E9%80%89%E4%B8%BE-01.jpg">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/%E5%93%A8%E5%85%B5%E8%8A%82%E7%82%B9%E5%8F%91%E7%8E%B0%E4%B8%BB%E8%8A%82%E7%82%B9%E6%8C%82%E4%BA%86%E9%87%8D%E6%96%B0%E9%80%89%E4%B8%BE.jpg">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/%E5%93%A8%E5%85%B5%E8%8A%82%E7%82%B9-6380%E8%A2%AB%E9%80%89%E4%B8%BE-6380%E6%8E%A7%E5%88%B6%E5%8F%B0.jpg">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/%E5%93%A8%E5%85%B5%E8%8A%82%E7%82%B9-6380%E8%A2%AB%E9%80%89%E4%B8%BE-6381%E6%8E%A7%E5%88%B6%E5%8F%B0.jpg">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/redis-38.png">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/redis-39.png">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/redis-40.png">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/redis-41.png">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/redis-42.png">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/redis-43.png">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/redis-28.png">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/twemproxy-%E5%90%AF%E5%8A%A803.jpg">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/%E5%90%AF%E5%8A%A8predixy-01jpg.jpg">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/predixy%E4%BD%BF%E7%94%A8.jpg">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/redis-28.png">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/redis-30.png">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/redis-31.png">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/redis-32.png">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/cluster-%E8%84%9A%E6%9C%AC%E5%90%AF%E5%8A%A8-01.jpg">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/cluster-%E8%84%9A%E6%9C%AC%E5%90%AF%E5%8A%A8-02.jpg">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/redis-29.png">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/cluster-%E6%99%AE%E9%80%9A%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%A8%A1%E5%BC%8F%E8%BF%9E%E6%8E%A5-01.jpg">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/cluster-%E9%9B%86%E7%BE%A4%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%A8%A1%E5%BC%8F%E8%BF%9E%E6%8E%A5.jpg">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/cluster-%E6%B8%85%E9%99%A4%E9%85%8D%E7%BD%AE%E8%BF%98%E5%8E%9F.jpg">
<meta property="og:image" content="http://yrlzero.gitee.io/images/linux/redis/cluster-%E7%A7%BB%E5%8A%A8%E6%A7%BD%E4%BD%8D-02.jpg">
<meta property="article:published_time" content="2021-04-13T13:08:29.509Z">
<meta property="article:modified_time" content="2021-05-08T14:39:00.760Z">
<meta property="article:author" content="yrl">
<meta property="article:tag" content="db">
<meta property="article:tag" content="redis">
<meta property="article:tag" content="nosql">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yrlzero.gitee.io/images/linux/redis/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E5%89%8D%E5%8F%B0%E5%90%AF%E5%8A%A8redis-01.jpg">

<link rel="canonical" href="http://yrlzero.gitee.io/2021/04/13/redis%E9%9B%86%E7%BE%A4/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>redis-集群 | yrl's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">yrl's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yrlzero.gitee.io/2021/04/13/redis%E9%9B%86%E7%BE%A4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="yrl">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="yrl's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          redis-集群
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-04-13 21:08:29" itemprop="dateCreated datePublished" datetime="2021-04-13T21:08:29+08:00">2021-04-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-08 22:39:00" itemprop="dateModified" datetime="2021-05-08T22:39:00+08:00">2021-05-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/linux/" itemprop="url" rel="index"><span itemprop="name">linux</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/linux/redis/" itemprop="url" rel="index"><span itemprop="name">redis</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="一、主从复制"><a href="#一、主从复制" class="headerlink" title="一、主从复制"></a>一、<code>主从复制</code></h2><h3 id="1、概念"><a href="#1、概念" class="headerlink" title="1、概念"></a>1、概念</h3><ul>
<li>一个master可以拥有多个slave。</li>
<li>master的复制是异步非阻塞的。</li>
<li>客户端可以使用wait命令请求同步复制某些特定数据。</li>
<li>正常连接情况下，master通过命令流来保持对slave的数据更新。</li>
<li>master与slave之间得到连接断开，slave在尝试与master重连后，会尝试获取与master断开期间丢失的命令流</li>
<li>当断开期间的数据无法重新同步时，slave会请求全量更新，master将以rdb快照方式将全量数据推送给slave，之后再进行增量更新。</li>
</ul>
<a id="more"></a>

<h3 id="2、复制原理"><a href="#2、复制原理" class="headerlink" title="2、复制原理"></a>2、复制原理</h3><ul>
<li>每个master都有一个replicationId用来表示与slave处于同一个主从复制中；<br>同时存在一个偏移量，用来记录上次发送给slave的数据，每次复制数据后该偏移量都会增加，即使没有slave链接master，它的offset也会增加。一对Replication ID, offset表示一个版本的数据</li>
<li>当slave连接到master后，会使用psync命令发送自己存储的旧replicationId和offset，master从积压的缓冲区找到对应版本的数据，开始增量复制推送给slave，如果缓冲区没有的话，master会进行全量RBD复制</li>
<li>全量复制，master后台fork一个进行产生一个rdb文件在本地磁盘，将rdb文件传输给slave保存在本地磁盘，slave加载到内存执行，无磁盘复制可以使用repl-diskless-sync 配置参数</li>
</ul>
<h3 id="3、准备"><a href="#3、准备" class="headerlink" title="3、准备"></a>3、准备</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建文件夹，拷贝redis配置，方便后续测试</span></span><br><span class="line">mkdir /usr/<span class="built_in">local</span>/<span class="built_in">test</span>-redis</span><br><span class="line">cp /etc/redis/* /</span><br><span class="line"></span><br><span class="line"><span class="comment">#注释日志输出，以便控制台观看</span></span><br><span class="line">vi 6379.conf</span><br><span class="line"><span class="comment">#logfile /var/log/redis_6379.log</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#关闭aof值测试rdb</span></span><br><span class="line">appendonly no</span><br><span class="line"></span><br><span class="line"><span class="comment">#关闭后台启动，前台启动方便查看</span></span><br><span class="line">daemonize no</span><br></pre></td></tr></table></figure>

<h3 id="4、启动redis"><a href="#4、启动redis" class="headerlink" title="4、启动redis"></a>4、启动redis</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">redis-server ./6379.conf </span><br><span class="line">redis-server ./6380.conf </span><br><span class="line">redis-server ./6380.conf</span><br></pre></td></tr></table></figure>

<p><img src="http://yrlzero.gitee.io/images/linux/redis/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E5%89%8D%E5%8F%B0%E5%90%AF%E5%8A%A8redis-01.jpg" alt=""></p>
<h3 id="5、slave追随master"><a href="#5、slave追随master" class="headerlink" title="5、slave追随master"></a>5、slave追随master</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">方式一：在进入6380、6381客户端，使用`replicaof host port`命令（5.0之前命令为`slaveof host port`），让从节点追随主节点</span><br><span class="line"></span><br><span class="line">方式二：在启动服务端时，使用`redis-server ./6380.conf --replicaof host port`命令，让从节点追随主节点</span><br><span class="line"></span><br><span class="line">方式三：在配置文件指定 <span class="comment"># replicaof &lt;masterip&gt; &lt;masterport&gt;</span></span><br></pre></td></tr></table></figure>

<p>从节点控制台日志</p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E4%BB%8E%E8%8A%82%E7%82%B9%E8%BF%BD%E9%9A%8F%E4%B8%BB%E8%8A%82%E7%82%B9-%E4%BB%8E%E8%8A%82%E7%82%B9%E6%8E%A7%E5%88%B6%E5%8F%B0%E6%97%A5%E5%BF%97-03.jpg" alt=""></p>
<p>主节点控制台日志</p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E4%BB%8E%E8%8A%82%E7%82%B9%E8%BF%BD%E9%9A%8F%E4%B8%BB%E8%8A%82%E7%82%B9-%E4%B8%BB%E8%8A%82%E7%82%B9%E6%8E%A7%E5%88%B6%E5%8F%B0%E6%97%A5%E5%BF%97-04.jpg" alt=""></p>
<h3 id="6、错误"><a href="#6、错误" class="headerlink" title="6、错误"></a>6、错误</h3><p>此时发现客户端宕机，重新启动客户端报如下错误</p>
<h4 id="6-1、问题1："><a href="#6-1、问题1：" class="headerlink" title="6.1、问题1："></a>6.1、问题1：</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">WARNING overcommit_memory is <span class="built_in">set</span> to 0! Background save may fail under low memory condition. To fix this issue add <span class="string">'vm.overcommit_memory = 1'</span> to /etc/sysctl.conf and <span class="keyword">then</span> reboot or run the <span class="built_in">command</span> <span class="string">'sysctl vm.overcommit_memory=1'</span> <span class="keyword">for</span> this to take effect.</span><br><span class="line">4562:M 13 Apr 2021 21:45:46.588 <span class="comment"># WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo madvise &gt; /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled (set to 'madvise' or 'never').</span></span><br><span class="line"></span><br><span class="line">警告:overcommit_memory设置为0!在内存不足的情况下，后台保存可能失败。要解决这个问题，添加‘vm’。overcommit_memory = 1<span class="string">' /etc/sysctl.conf，然后重启或执行'</span>sysctl vm. conf <span class="string">'命令。overcommit_memory=1'</span>让它生效。</span><br><span class="line"><span class="comment">#警告:你的内核已经启用了透明的大页面(THP)支持。这会造成Redis的延迟和内存使用问题。要解决这个问题，以root权限运行'echo madvise &gt; /sys/kernel/mm/transparent_hugepage/enabled'命令，并将其添加到/etc/rc.本地，以便在重新启动后保留设置。禁用THP后必须重新启动Redis(设置为'madvise'或'never')。</span></span><br></pre></td></tr></table></figure>

<p>执行<code>sysctl vm.overcommit_memory=1</code>解决以上问题</p>
<h4 id="6-2、问题2："><a href="#6-2、问题2：" class="headerlink" title="6.2、问题2："></a>6.2、问题2：</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">WARNING you have Transparent Huge Pages (THP) support enabled <span class="keyword">in</span> your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the <span class="built_in">command</span> <span class="string">'echo madvise &gt; /sys/kernel/mm/transparent_hugepage/enabled'</span> as root, and add it to your /etc/rc.local <span class="keyword">in</span> order to retain the setting after a reboot. Redis must be restarted after THP is disabled (<span class="built_in">set</span> to <span class="string">'madvise'</span> or <span class="string">'never'</span>).</span><br><span class="line"></span><br><span class="line">您的内核中启用了透明的大页面(THP)支持。这会造成Redis的延迟和内存使用问题。要解决这个问题，以root权限运行<span class="string">'echo madvise &gt; /sys/kernel/mm/transparent_hugepage/enabled'</span>命令，并将其添加到/etc/rc.本地，以便在重新启动后保留设置。禁用THP后必须重新启动Redis(设置为<span class="string">'madvise'</span>或<span class="string">'never'</span>)。</span><br></pre></td></tr></table></figure>

<p>执行<code>echo madvise &gt; /sys/kernel/mm/transparent_hugepage/enabled</code>解决以上问题</p>
<h4 id="6-3、问题3："><a href="#6-3、问题3：" class="headerlink" title="6.3、问题3："></a>6.3、问题3：</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is <span class="built_in">set</span> to the lower value of 128.</span><br><span class="line"></span><br><span class="line">由于/proc/sys/net/core/somaxconn被设置为较低的值128,TCP backlog设置511无法执行。</span><br></pre></td></tr></table></figure>

<p>执行<code>echo 511 &gt; /proc/sys/net/core/somaxconn</code>解决以上问题</p>
<h4 id="6-4、问题4："><a href="#6-4、问题4：" class="headerlink" title="6.4、问题4："></a>6.4、问题4：</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">5499:M 13 Apr 2021 21:58:45.198 <span class="comment"># Server initialized</span></span><br><span class="line">5499:M 13 Apr 2021 21:58:45.198 * Loading RDB produced by version 6.0.9</span><br><span class="line">5499:M 13 Apr 2021 21:58:45.198 * RDB age 1191 seconds</span><br><span class="line">5499:M 13 Apr 2021 21:58:45.198 * RDB memory usage when created 1.85 Mb</span><br><span class="line">5499:M 13 Apr 2021 21:58:45.198 <span class="comment"># The RDB file contains module data I can't load: no matching module 'MBbloom--'</span></span><br></pre></td></tr></table></figure>

<p>此时仍无法启动，需要到持久化目录<code>/var/lib/redis/6381</code>下处理rdb文件<code>mv dump.rdb dump.rdb.bak</code>，此时可以正常启动</p>
<h3 id="7、slave升级为master"><a href="#7、slave升级为master" class="headerlink" title="7、slave升级为master"></a>7、slave升级为master</h3><p>当主节点宕机时，我们需要手动进行故障转移，将从节点升级为主节点</p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E4%BB%8E%E8%8A%82%E7%82%B9%E7%9B%91%E6%8E%A7%E5%88%B0%E4%B8%BB%E8%8A%82%E7%82%B9%E5%AE%95%E6%9C%BA-05.jpg" alt="从节点监控到主节点宕机"></p>
<p>从节点客户端执行<code>replicaof no one</code>指令，将自己从slave升级为master</p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E4%BB%8E%E8%8A%82%E7%82%B9%E5%B0%86%E8%87%AA%E5%B7%B1%E5%8D%87%E7%BA%A7%E4%B8%BA%E4%B8%BB%E8%8A%82%E7%82%B9-06.jpg" alt="从节点升级为主节点"></p>
<h3 id="8、配置"><a href="#8、配置" class="headerlink" title="8、配置"></a>8、配置</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># slave在首次接收master数据时，可以在slave中配置同步期间是否接收旧数据的访问，在首次同步之后，旧数据会被删除，然后再主线程加载新数据，此时slave会阻塞</span></span><br><span class="line">replica-serve-stale-data yes  </span><br><span class="line"></span><br><span class="line"><span class="comment">#从节点是否开启只读模式</span></span><br><span class="line">replica-read-only yes </span><br><span class="line"></span><br><span class="line"><span class="comment">#是否采用无磁盘模式传输，no表示走磁盘，yes走网络传输</span></span><br><span class="line">repl-diskless-sync no </span><br><span class="line"></span><br><span class="line"><span class="comment">#增量复制，当redis挂掉之后又恢复，主节点可以增量传输数据过来，但是增量的数据与当前的数据存在偏差，从节点可以通过传送offset从主节点再次拉回数据，此配置大小会关系到redis内存维护的队列大小，此操作的成功与否，数据量大于这个值会造成溢出</span></span><br><span class="line"><span class="comment"># repl-backlog-size 1mb </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果至少有 3 个 slave ，并且滞后小于 10 秒，则写入将被接受,如果条件不满足master的写操作将被拒绝。</span></span><br><span class="line"><span class="comment"># min-replicas-to-write 3</span></span><br><span class="line"><span class="comment"># min-replicas-max-lag 10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果master节点设置了密码，需要在此处进行配置对应表的访问密码</span></span><br><span class="line"><span class="comment"># masterauth &lt;master-password&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置追随的master节点</span></span><br><span class="line"><span class="comment"># replicaof &lt;masterip&gt; &lt;masterport&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="9、总结"><a href="#9、总结" class="headerlink" title="9、总结"></a>9、总结</h3><p>1、从节点追随主节点之后，旧数据会被删除，同时非阻塞方式同步主节点数据</p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E4%BB%8E%E8%8A%82%E7%82%B9%E8%BF%BD%E9%9A%8F%E5%89%8D%E5%90%8E%E6%95%B0%E6%8D%AE%E5%8F%98%E5%8C%96-05.jpg" alt=""></p>
<p>2、从节点只能读，不能写（可修改配置改变）</p>
<p>3、主节点出现故障时，需要人工维护升级新的主节点</p>
<h2 id="二、哨兵模式"><a href="#二、哨兵模式" class="headerlink" title="二、哨兵模式"></a>二、<code>哨兵模式</code></h2><h3 id="1、概念-1"><a href="#1、概念-1" class="headerlink" title="1、概念"></a>1、概念</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.通过连接master获取slave的信息</span><br><span class="line">2.通过psubscribe正则方式订阅发布的信息,从而发现其他哨兵节点</span><br><span class="line">3.监控主从节点是否正常</span><br><span class="line">3.自动故障转移</span><br><span class="line">4.使用投票机制选举master</span><br></pre></td></tr></table></figure>

<h3 id="2、Sentinel相互发现"><a href="#2、Sentinel相互发现" class="headerlink" title="2、Sentinel相互发现"></a>2、Sentinel相互发现</h3><ul>
<li>每个Sentinel会以每两秒一次的频率，通过发布与订阅功能，向被它监视的所有master和slave的 sentinel:hello 频道发送一条信息，信息中包含了该Sentinel的IP 地址、端口号和运行ID （runid）。</li>
<li>每个Sentinel都订阅了被它监视的所有master和slave的sentinel:hello 频道,查找之前未出现过的sentinel（looking for unknown sentinels）。当一个Sentinel 发现一个新的Sentinel时，它会将新的Sentinel添加到一个列表中，这个列表保存了Sentinel已知的，监视同一个主服务器的所有其他Sentinel。</li>
<li>Sentinel 发送的信息中还包括完整的主服务器当前配置（configuration）。 如果一个 Sentinel 包含的主服务器配置比另一个 Sentinel 发送的配置要旧， 那么这个 Sentinel 会立即升级到新配置上。</li>
<li>在将一个新Sentinel添加到监视主服务器的列表上面之前，Sentinel会先检查列表中是否已经包含了和要添加的Sentinel拥有相同运行ID或者相同地址（包括IP地址和端口号）的 Sentinel ，如果是的话，Sentinel会先移除列表中已有的那些拥有相同运行ID或者相同地址的Sentinel， 然后再添加新Sentinel。</li>
</ul>
<h3 id="3、Sentinel对master的故障判定"><a href="#3、Sentinel对master的故障判定" class="headerlink" title="3、Sentinel对master的故障判定"></a>3、Sentinel对master的故障判定</h3><p>1)、 Sentinel以每秒钟一次的频率向它所知的master、slave以及其他 Sentinel 实例发送一个 PING 命令,如果距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值，那么这个实例会被 Sentinel 标记为主观下线。一个有效回复可以是：+PONG 、-LOADING 或者 -MASTERDOWN ，其余回复或者没有回复都算是无效回复。<br>2)、当master标记为ODOWN(主观下线)后，用通过向另一个 Sentinel 发送 SENTINEL is-master-down-by-addr 命令来询问对方是否认为给定的服务器已下线。<br>        2.1)、当有足够数量的 Sentinel（至少要达到配置文件指定的数量quorum）在指定的时间范围内同意这一判断， 那么这个主服务器被标记为客观下线。<br>        2.2)、当没有足够数量的 Sentinel 同意主服务器已经下线， 主服务器的客观下线状态就会被移除。 当主服务器重新向 Sentinel 的 PING 命令返回有效回复时， 主服务器的主观下线状态就会被移除<br>3)、在一般情况下， 每个 Sentinel 会以每 10 秒一次的频率向它已知的所有master和slave发送 INFO 命令。 当一个master被 Sentinel 标记为客观下线时， Sentinel 向下线master的所有slave发送 INFO 命令的频率会从 10 秒一次改为每秒一次。</p>
<h3 id="4、选举新的master"><a href="#4、选举新的master" class="headerlink" title="4、选举新的master"></a>4、选举新的master</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">首先标记master为ODOWN状态的Sentinel使用以下规则从slave中来选取新的master：</span><br><span class="line">1、被标记为主观下线、已断线、或者最后一次回复 PING 命令的时间大于五秒钟的从服务器都会被淘汰。</span><br><span class="line">2、与失效主服务器连接断开的时长超过 down-after-milliseconds 选项指定的时长十倍的从服务器都会被淘汰。</span><br><span class="line">3、在经历了以上两轮淘汰之后剩下来的从服务器中， 选出复制偏移量（replication offset）最大的那个从服务器作为新的主服务器； </span><br><span class="line">4、如果复制偏移量不可用， 或者从服务器的复制偏移量相同， 那么带有最小运行 ID 的那个从服务器成为新的主服务器。</span><br></pre></td></tr></table></figure>

<h3 id="5、准备"><a href="#5、准备" class="headerlink" title="5、准备"></a>5、准备</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#配置文件参考源码目录下/usr/local/redis-6.0.9/sentinel.conf</span></span><br><span class="line"></span><br><span class="line">创建配置文件</span><br><span class="line">vi 26379.conf</span><br><span class="line"></span><br><span class="line">port 26379 <span class="comment"># 指定当前哨兵端口号</span></span><br><span class="line">sentinel monitor mymaster 127.0.0.1 6379 2 <span class="comment"># 指定哨兵需要监控的主节点ip port 投票达成一致数量</span></span><br></pre></td></tr></table></figure>

<h3 id="6、配置"><a href="#6、配置" class="headerlink" title="6、配置"></a>6、配置</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#如果需要监控监控的master设置了密码，需要在此处设置</span></span><br><span class="line"><span class="comment"># sentinel auth-pass &lt;master-name&gt; &lt;password&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="7、启动哨兵节点"><a href="#7、启动哨兵节点" class="headerlink" title="7、启动哨兵节点"></a>7、启动哨兵节点</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">启动方式一：redis-server ./26379.conf --sentinel</span><br><span class="line">启动方式二：redis-sentinel ./26381.conf</span><br></pre></td></tr></table></figure>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/%E5%93%A8%E5%85%B5%E8%8A%82%E7%82%B9%E5%90%AF%E5%8A%A8-01.jpg" alt=""></p>
<h3 id="8、选举新master节点"><a href="#8、选举新master节点" class="headerlink" title="8、选举新master节点"></a>8、选举新master节点</h3><p>当master节点宕机，哨兵节点过半以上检测到之后会重新选举新的master节点</p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/%E5%93%A8%E5%85%B5%E8%8A%82%E7%82%B9%E5%8F%91%E7%8E%B0%E4%B8%BB%E8%8A%82%E7%82%B9%E6%8C%82%E4%BA%86%E9%87%8D%E6%96%B0%E9%80%89%E4%B8%BE-01.jpg" alt=""></p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/%E5%93%A8%E5%85%B5%E8%8A%82%E7%82%B9%E5%8F%91%E7%8E%B0%E4%B8%BB%E8%8A%82%E7%82%B9%E6%8C%82%E4%BA%86%E9%87%8D%E6%96%B0%E9%80%89%E4%B8%BE.jpg" alt=""></p>
<p>slave节点升级为master节点</p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/%E5%93%A8%E5%85%B5%E8%8A%82%E7%82%B9-6380%E8%A2%AB%E9%80%89%E4%B8%BE-6380%E6%8E%A7%E5%88%B6%E5%8F%B0.jpg" alt=""></p>
<p>另一个slave检测到新的master主节点产生并追随</p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/%E5%93%A8%E5%85%B5%E8%8A%82%E7%82%B9-6380%E8%A2%AB%E9%80%89%E4%B8%BE-6381%E6%8E%A7%E5%88%B6%E5%8F%B0.jpg" alt=""></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>1、哨兵通过主节点获取从节点信息，同时发布订阅方式发现其他哨兵节点信息</p>
<p>2、主节点宕机后，哨兵节点重新选举新的主节点，做到故障转移，不需要人工处理</p>
<p>3、master节点存在已经过期的key，复制到了slave，那当master的“访问过期”和“定期过期”机制没有被触发时，该key没有被删除，客户端链接slave查询该key时出现什么情况？推测：判断过期返回不存在，过期的key不处理，等待master处理后同步del指令</p>
<h2 id="三、分区"><a href="#三、分区" class="headerlink" title="三、分区"></a>三、分区</h2><h3 id="1、概念-2"><a href="#1、概念-2" class="headerlink" title="1、概念"></a>1、概念</h3><h4 id="1-1、不同端的分区"><a href="#1-1、不同端的分区" class="headerlink" title="1.1、不同端的分区"></a>1.1、不同端的分区</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">客户端分区:</span><br><span class="line">	由客户端根据一定的算法逻辑计算出该key应该与哪一个redis实例交互</span><br><span class="line">	用户客户端自己实现逻辑</span><br><span class="line">代理分区:</span><br><span class="line">	客户端不需要理会如何分区，请求发送给代理，有代理觉得链接哪一个redis实例</span><br><span class="line">	twemproxy、predixy</span><br><span class="line">查询路由:</span><br><span class="line">	客户端随机请求任意的redis实例，redis将请求转发给正确的redis节点处理</span><br><span class="line">	redis cluster</span><br></pre></td></tr></table></figure>

<h4 id="1-2、优缺点"><a href="#1-2、优缺点" class="headerlink" title="1.2、优缺点"></a>1.2、优缺点</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">分区优点</span><br><span class="line">	可以让redis管理更大的内存</span><br><span class="line">	分布在不同的计算机利用不同计算机的计算能力，使redis的计算能力得到提升</span><br><span class="line">分区的缺点：</span><br><span class="line">	多个key不在统一分区无法使用聚合、事务等操作</span><br><span class="line">	动态扩容和收缩需要对数据进行再平衡（预分片可以解决这个问题）</span><br></pre></td></tr></table></figure>

<h4 id="1-3、预分片"><a href="#1-3、预分片" class="headerlink" title="1.3、预分片"></a>1.3、预分片</h4><p>​    因为redis实例占用的内存很小，在一台机子提前启用多台redis以分布式方式运行，随着数据不断增加，需要做的只是将redis实例迁移到另外的计算机中，不需要考虑重新分区</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.新的服务器启动新的redis实例</span><br><span class="line">2.配置为需要迁移的旧redis的slave（此操作可以同步数据）</span><br><span class="line">3.更新分片映射的旧实例ip为新实例ip</span><br><span class="line">4.客户端连接新的redis实例执行SLAVEOF NO ONE命令，将新实例升级为master</span><br><span class="line">5.停止旧的redis实例</span><br></pre></td></tr></table></figure>

<h3 id="2、分区算法"><a href="#2、分区算法" class="headerlink" title="2、分区算法"></a>2、分区算法</h3><h4 id="2-1、普通Hash算法（modula）"><a href="#2-1、普通Hash算法（modula）" class="headerlink" title="2.1、普通Hash算法（modula）"></a>2.1、普通Hash算法（modula）</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">比如你有 N 个 &#96;redis&#96;实例，那么如何将一个&#96;key&#96;映射到&#96;redis&#96;上呢，你很可能会采用类似下面的通用方法计算 key的 hash 值，然后均匀的映射到到 N 个 &#96;redis&#96;上：</span><br><span class="line">　　&#96;hash(key)%N&#96;</span><br><span class="line">　　如果增加一个&#96;redis&#96;，映射公式变成了 &#96;hash(key)%(N+1)&#96;</span><br><span class="line">　　如果一个&#96;redis&#96;宕机了，映射公式变成了 &#96;hash(key)%(N-1)&#96;</span><br><span class="line">　　在这两种情况下，每一个&#96;redis&#96;管理的数据全部要重新计算移动，几乎所有的缓存都失效了。会导致数据库访问的压力陡增，严重情况，还可能导致数据库宕机。</span><br></pre></td></tr></table></figure>

<h4 id="2-2、随机分配算法-random"><a href="#2-2、随机分配算法-random" class="headerlink" title="2.2、随机分配算法(random)"></a>2.2、随机分配算法(random)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">随机将数据分发到Redis集群中，Client无法准确地从某台机器获取相对的数据，该做法常用于消息队列中。</span><br></pre></td></tr></table></figure>

<h4 id="2-3、一致性Hash算法-ketama"><a href="#2-3、一致性Hash算法-ketama" class="headerlink" title="2.3、一致性Hash算法(ketama)"></a>2.3、一致性Hash算法(ketama)</h4><ol>
<li>将内存想象成一个环，由于hash值有32位，因此将内存分出2 ^32（0~2 ^32-1）个地址</li>
<li>将节点的IP+算法确定唯一的哈希值，之后在内存中确定节点的位置</li>
<li>当保存数据时，根据key进行哈希运算，确定唯一的一个位置</li>
<li>根据当前<code>key</code>位置<strong>顺时针</strong>查找最近的<code>node</code>节点进行挂载（在内存中，加法计算快于减法运算，因此采用顺时针查找）</li>
</ol>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/redis-38.png" alt=""></p>
<p>将各个服务器使用<code>Hash</code>进行一个哈希，具体可以选择服务器的ip或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置。</p>
<p>假设将中四台服务器使用ip地址哈希后在环空间的位置如下：</p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/redis-39.png" alt=""></p>
<p>将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。</p>
<p>假设4个存储对象 Object A、B、C、D，经过对 Key 的哈希计算后，它们的位置如下：</p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/redis-40.png" alt=""></p>
<p>根据一致性哈希算法，数据A会被定为到<code>Node A</code>上，B被定为到<code>Node B</code>上，C被定为到<code>Node C</code>上，D被定为到<code>Node D</code>上。</p>
<h5 id="容错性和可扩展性"><a href="#容错性和可扩展性" class="headerlink" title="容错性和可扩展性"></a>容错性和可扩展性</h5><p>假设Node C不幸宕机，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到<code>Node D</code>。一般的，在一致性哈希算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。</p>
<p>如果在系统中增加一台服务器Node X，如下图所示：</p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/redis-41.png" alt=""></p>
<p>此时对象Object A、B、D不受影响，只有对象C需要重定位到新的Node X 。一般的，在一致性哈希算法中，如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响。</p>
<p>综上所述，一致性哈希算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。</p>
<p>如果这时候新增了一个结点，对原来缓存的一部分数据的访问将会落到新增的结点上，但是这时候结点并没有数据缓存，<strong>它将去数据库中查找并缓存，原先已经缓存数据的结点需要通过淘汰算法（LRU）淘汰数据，它并没有从原缓存结点复制数据到新节点中。</strong></p>
<h5 id="虚拟节点"><a href="#虚拟节点" class="headerlink" title="虚拟节点"></a>虚拟节点</h5><p><strong>但一致性哈希算法也有一个严重的问题，就是数据倾斜</strong>。如果在分片的集群中，节点太少，并且分布不均，一致性哈希算法就会出现部分节点数据太多，部分节点数据太少。也就是说无法控制节点存储数据的分配。如下图，大部分数据都在 A 上了，B 的数据比较少。</p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/redis-42.png" alt=""></p>
<p>节点数越少，越容易出现节点在哈希环上的分布不均匀，导致各节点映射的对象数量严重不均衡(数据倾斜)；相反，节点数越多越密集，数据在哈希环上的分布就越均匀。</p>
<p>以删除节点为例，假设删除了<code>Node B</code>节点，原来<code>Node B</code>节点的数据将转移到<code>Node C</code>上，这样<code>Node C</code>的内存使用率会骤增，如果<code>Node B</code>上存在热点数据，<code>Node C</code>会扛不住甚至会可能挂掉，挂掉之后数据又转移给<code>Node D</code>,如此循环会造成所有节点崩溃，也就是<strong>缓存雪崩</strong>。</p>
<p>为了解决雪崩现象和数据倾斜现象，提出了虚拟节点这个概念。就是将真实节点计算多个哈希形成多个虚拟节点并放置到哈希环上，<strong>定位算法不变，只是多了一步虚拟节点到真实节点映射的过程</strong></p>
<p>但实际部署的物理节点有限，我们可以用有限的物理节点，虚拟出足够多的虚拟节点(<code>Virtual Node</code>)，最终达到数据在哈希环上均匀分布的效果。</p>
<p>如下图，实际只部署了2个节点 Node A/B，每个节点都复制成3倍，结果看上去是部署了6个节点。可以想象，当复制倍数为 2^32 时，就达到绝对的均匀，通常可取复制倍数为32或更高。</p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/redis-43.png" alt=""></p>
<p><strong>这就解决了雪崩的问题，当某个节点宕机后，其数据并没有全部分配给某一个节点，而是被分到了多个节点，数据倾斜的问题也随之解决</strong>。</p>
<h5 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h5><p>一致性哈希算法，既可以在客户端实现，也可以在中间件上实现（如 proxy）。在客户端实现中，当客户端初始化的时候，需要初始化一张预备的 Redis 节点的映射表：hash(key)=&gt; . 这有一个缺点，假设有多个客户端，当映射表发生变化的时候，多个客户端需要同时拉取新的映射表。</p>
<p>另一个种是中间件（proxy）的实现方法，即在客户端和 Redis 节点之间加多一个代理，代理经过哈希计算后将对应某个 key 的请求分发到对应的节点，一致性哈希算法就在中间件里面实现。可以发现，twemproxy 就是这么做的。</p>
<h4 id="2-4、哈希槽"><a href="#2-4、哈希槽" class="headerlink" title="2.4、哈希槽"></a>2.4、哈希槽</h4><p><strong><code>redis</code> 集群（<code>cluster</code>）并没有选用上面一致性哈希，而是采用了哈希槽（<code>slot</code>）的这种概念</strong>。主要的原因就是上面所说的，<strong>一致性哈希算法对于数据分布、节点位置的控制并不是很友好</strong>。</p>
<p>首先哈希槽其实是两个概念，第一个是哈希算法。<code>redis cluster</code> 的 <code>hash</code> 算法不是简单的<code>hash</code>()，而是 <code>crc16</code> 算法，一种校验算法。另外一个就是槽位的概念，空间分配的规则。</p>
<p>其实哈希槽的本质和一致性哈希算法非常相似，不同点就是对于哈希空间的定义。一致性哈希的空间是一个圆环，节点分布是基于圆环的，无法很好的控制数据分布。而 <code>redis cluster</code> 的槽位空间是自定义分配的，类似于 <code>windows</code> 盘分区的概念。这种分区是可以自定义大小，自定义位置的。</p>
<p><code>redis cluster</code> 包含了16384个哈希槽，每个 <code>key</code> 通过计算后都会落在具体一个槽位上，而这个槽位是属于哪个存储节点的，则由用户自己定义分配。例如机器硬盘小的，可以分配少一点槽位，硬盘大的可以分配多一点。如果节点硬盘都差不多则可以平均分配。<strong>所以哈希槽这种概念很好地解决了一致性哈希的弊端</strong>。</p>
<p><strong>当有新节点加入时，它不再需要像一致性Hash算法那样把每个<code>key</code>取出来重新计算<code>hash</code>值，只需要从旧节点中将新节点应该缓存的槽位数据拷贝到新节点中即可。</strong></p>
<p>另外在容错性和扩展性上，表象与一致性哈希一样，都是对受影响的数据进行转移。而哈希槽本质上是对槽位的转移，把故障节点负责的槽位转移到其他正常的节点上。扩展节点也是一样，把其他节点上的槽位转移到新的节点上。</p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/redis-28.png" alt=""></p>
<p><strong>弊端是聚合操作很难实现，并且不支持跨机器事务，但是提供了Hash Tag让用户控制需要计算的Key都集中在一个Redis中。</strong></p>
<h3 id="3、代理分区-TwemProxy"><a href="#3、代理分区-TwemProxy" class="headerlink" title="3、代理分区-TwemProxy"></a>3、代理分区-<a href="https://github.com/twitter/twemproxy" target="_blank" rel="noopener"><code>TwemProxy</code></a></h3><h4 id="3-1、安装"><a href="#3-1、安装" class="headerlink" title="3.1、安装"></a>3.1、安装</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> git@github.com:twitter/twemproxy.git</span><br><span class="line"><span class="built_in">cd</span> twemproxy</span><br><span class="line">autoreconf -fvi</span><br><span class="line">./configure --<span class="built_in">enable</span>-debug=full</span><br><span class="line">make</span><br><span class="line"></span><br><span class="line"><span class="comment">#此操作是为了之后可以使用service twemproxy start/stop等命令操作</span></span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/twemproxy/scripts</span><br><span class="line">cp nutcracker.init /etc/init.d/twemproxy</span><br><span class="line"><span class="built_in">cd</span> /etc/init.d/</span><br><span class="line">chmod +x twemproxy</span><br><span class="line"></span><br><span class="line"><span class="comment">#可以看到需要在这个目录下创建此配置 OPTIONS="-d -c /etc/nutcracker/.yml"</span></span><br><span class="line">more twemproxy </span><br><span class="line"></span><br><span class="line">进入源码目录</span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/twemproxy/conf</span><br><span class="line">cp ./* /etc/nutcracker</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/twemproxy/src</span><br><span class="line">cp nutcracker /usr/bin <span class="comment">#之后再操作系统任意地方可以使用nutcracker命令</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /etc/nutcracker</span><br><span class="line">cp nutcracker.yml nutcracker.yml.bak</span><br></pre></td></tr></table></figure>

<h4 id="3-2、配置"><a href="#3-2、配置" class="headerlink" title="3.2、配置"></a>3.2、配置</h4><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">nutcracker.yml</span></span><br><span class="line"></span><br><span class="line"><span class="attr">alpha:</span></span><br><span class="line">  <span class="attr">listen:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:22121</span></span><br><span class="line">  <span class="attr">hash:</span> <span class="string">fnv1a_64</span></span><br><span class="line">  <span class="attr">distribution:</span> <span class="string">ketama</span></span><br><span class="line">  <span class="attr">auto_eject_hosts:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">redis:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">server_retry_timeout:</span> <span class="number">2000</span></span><br><span class="line">  <span class="attr">server_failure_limit:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">servers:</span></span><br><span class="line">   <span class="bullet">-</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:6379:1</span> <span class="comment">#1指的是权重</span></span><br><span class="line">   <span class="bullet">-</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:9380:1</span></span><br></pre></td></tr></table></figure>

<h4 id="3-3、手动启动redis"><a href="#3-3、手动启动redis" class="headerlink" title="3.3、手动启动redis"></a>3.3、手动启动redis</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#直接指定端口启动的话，会将当前目录作为持久目录</span></span><br><span class="line">mkdir /usr/<span class="built_in">local</span>/<span class="built_in">test</span>-redis/6379_data</span><br><span class="line">redis-server --port 6379</span><br><span class="line"></span><br><span class="line">mkdir /usr/<span class="built_in">local</span>/<span class="built_in">test</span>-redis/6380_data</span><br><span class="line">redis-server --port 6380</span><br></pre></td></tr></table></figure>

<h4 id="3-4、启动twemproxy"><a href="#3-4、启动twemproxy" class="headerlink" title="3.4、启动twemproxy"></a>3.4、启动twemproxy</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service twemproxy start</span><br></pre></td></tr></table></figure>

<p><img src="http://yrlzero.gitee.io/images/linux/redis/twemproxy-%E5%90%AF%E5%8A%A803.jpg" alt=""></p>
<h4 id="3-5、通过代理连接redis"><a href="#3-5、通过代理连接redis" class="headerlink" title="3.5、通过代理连接redis"></a>3.5、通过代理连接redis</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#数据分区，不支持keys、watch、MULTI等命令</span></span><br><span class="line">redis-cli -p 22121</span><br></pre></td></tr></table></figure>

<h3 id="4、代理分区-Predixy"><a href="#4、代理分区-Predixy" class="headerlink" title="4、代理分区-Predixy"></a>4、代理分区-<a href="https://github.com/joyieldInc/predixy/releases" target="_blank" rel="noopener"><code>Predixy</code></a></h3><p><a href="https://github.com/joyieldInc/predixy/blob/master/README_CN.md" target="_blank" rel="noopener">中文文档</a></p>
<h4 id="4-1、安装"><a href="#4-1、安装" class="headerlink" title="4.1、安装"></a>4.1、安装</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/joyieldInc/predixy/releases/download/1.0.5/predixy-1.0.5-bin-amd64-linux.tar.gz</span><br><span class="line">tar xf predixy-1.0.5-bin-amd64-linux.tar.gz</span><br></pre></td></tr></table></figure>

<h4 id="4-2、predixy相关配置"><a href="#4-2、predixy相关配置" class="headerlink" title="4.2、predixy相关配置"></a>4.2、predixy相关配置</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#修改predixy配置</span></span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/predixy/predixy-1.0.5/conf</span><br><span class="line">vi predixy.conf </span><br><span class="line"></span><br><span class="line"><span class="comment">################################### GENERAL ####################################</span></span><br><span class="line"><span class="comment"># 开放predixy绑定的ip端口</span></span><br><span class="line">Bind 127.0.0.1:7617</span><br><span class="line"><span class="comment"># Bind 0.0.0.0:7617</span></span><br><span class="line"><span class="comment"># Bind /tmp/predixy</span></span><br><span class="line"><span class="comment">################################### SERVERS ####################################</span></span><br><span class="line"><span class="comment"># Include cluster.conf</span></span><br><span class="line"><span class="comment">#加载sentinel相关配置</span></span><br><span class="line">Include sentinel.conf</span><br><span class="line"><span class="comment"># Include try.conf</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#修改predixy的sentinel配置</span></span><br><span class="line">vim sentinel.conf</span><br><span class="line">SentinelServerPool &#123;</span><br><span class="line">    Databases 16</span><br><span class="line">    Hash crc16</span><br><span class="line">    HashTag <span class="string">"&#123;&#125;"</span></span><br><span class="line">    Distribution modula</span><br><span class="line">    MasterReadPriority 60</span><br><span class="line">    StaticSlaveReadPriority 50</span><br><span class="line">    DynamicSlaveReadPriority 50</span><br><span class="line">    RefreshInterval 1</span><br><span class="line">    ServerTimeout 1</span><br><span class="line">    ServerFailureLimit 10</span><br><span class="line">    ServerRetryTimeout 1</span><br><span class="line">    KeepAlive 120</span><br><span class="line">    Sentinels &#123;</span><br><span class="line">        + 127.0.0.1:26379  <span class="comment">#配置哨兵节点</span></span><br><span class="line">        + 127.0.0.1:26380  <span class="comment">#配置哨兵节点</span></span><br><span class="line">        + 127.0.0.1:26381  <span class="comment">#配置哨兵节点</span></span><br><span class="line">    &#125;</span><br><span class="line">    Group mySentinel001 &#123; <span class="comment">#配置redis主从分组名</span></span><br><span class="line">    &#125;</span><br><span class="line">    Group mySentinel002 &#123; <span class="comment">#配置redis主从分组名</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="4-3、sentinel配置"><a href="#4-3、sentinel配置" class="headerlink" title="4.3、sentinel配置"></a>4.3、sentinel配置</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">port 26379</span><br><span class="line">sentinel monitor mySentinel001 127.0.0.1 36379 2</span><br><span class="line">sentinel monitor mySentinel002 127.0.0.1 46379 2</span><br><span class="line"></span><br><span class="line">port 26380</span><br><span class="line">sentinel monitor mySentinel001 127.0.0.1 36379 2</span><br><span class="line">sentinel monitor mySentinel002 127.0.0.1 46379 2</span><br><span class="line"></span><br><span class="line">port 26381</span><br><span class="line">sentinel monitor mySentinel001 127.0.0.1 36379 2</span><br><span class="line">sentinel monitor mySentinel002 127.0.0.1 46379 2</span><br></pre></td></tr></table></figure>

<h4 id="4-4、启动sentinel"><a href="#4-4、启动sentinel" class="headerlink" title="4.4、启动sentinel"></a>4.4、启动sentinel</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">redis-server 26379.conf --sentinel</span><br><span class="line">redis-server 26380.conf --sentinel</span><br><span class="line">redis-server 26381.conf --sentinel</span><br></pre></td></tr></table></figure>

<h4 id="4-5、启动redis主从"><a href="#4-5、启动redis主从" class="headerlink" title="4.5、启动redis主从"></a>4.5、启动redis主从</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mkdir 36379</span><br><span class="line">mkdir 36380</span><br><span class="line">mkdir 46379</span><br><span class="line">mkdir 46380</span><br><span class="line">redis-sever --port 36379</span><br><span class="line">redis-server --port 36380 --replicaof 127.0.0.1 36379</span><br><span class="line">redis-sever --port 46379</span><br><span class="line">redis-server --port 46380 --replicaof 127.0.0.1 46379</span><br></pre></td></tr></table></figure>

<h4 id="4-6、启动predixy"><a href="#4-6、启动predixy" class="headerlink" title="4.6、启动predixy"></a>4.6、启动predixy</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/predixy/predixy-1.0.5/bin</span><br><span class="line">./predixy ../conf/predixy.conf</span><br></pre></td></tr></table></figure>

<p><img src="http://yrlzero.gitee.io/images/linux/redis/%E5%90%AF%E5%8A%A8predixy-01jpg.jpg" alt=""></p>
<h4 id="4-7、通过代理连接redis"><a href="#4-7、通过代理连接redis" class="headerlink" title="4.7、通过代理连接redis"></a>4.7、通过代理连接redis</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#代理分区，因为sentinel监控了两套主从，不支持keys、watch、MULTI等命令，使用单套主从则可以</span></span><br><span class="line">redis-cli -p 7167</span><br></pre></td></tr></table></figure>

<p><img src="http://yrlzero.gitee.io/images/linux/redis/predixy%E4%BD%BF%E7%94%A8.jpg" alt=""></p>
<h3 id="5、查询路由分区-Redis-Cluster"><a href="#5、查询路由分区-Redis-Cluster" class="headerlink" title="5、查询路由分区-Redis-Cluster"></a>5、查询路由分区-<code>Redis-Cluster</code></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">无需&#96;proxy&#96;代理，客户端直接与&#96;redis&#96;集群的每个节点连接，根据同样的&#96;hash&#96;算法计算出&#96;key&#96;对应的&#96;slot&#96;，然后直接在&#96;slot&#96;对应的&#96;redis&#96;节点上执行命令。</span><br><span class="line"></span><br><span class="line">在&#96;redis&#96;看来，响应时间是最苛刻的条件，增加一层带来的开销是&#96;redis&#96;不能接受的。因此，&#96;redis&#96;实现了客户端对节点的直接访问，**为了去中心化，节点之间通过&#96;gossip&#96;协议交换互相的状态，以及探测新加入的节点信息**。&#96;redis&#96;集群支持动态加入节点，动态迁移&#96;slot&#96;，以及自动故障转移。</span><br></pre></td></tr></table></figure>

<h4 id="5-1、slot分配"><a href="#5-1、slot分配" class="headerlink" title="5.1、slot分配"></a>5.1、slot分配</h4><p><strong>redis集群模式使用公式 <code>CRC16(key) % 16384</code> 来计算键<code>key</code>属于哪个槽， 其中 <code>CRC16(key)</code> 语句用于计算键 <code>key</code> 的 <code>CRC16</code> 校验和 。集群中的每个节点负责处理一部分哈希槽。</strong></p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/redis-28.png" alt=""></p>
<p> 举个例子， 一个集群可以有三个节点， 其中：</p>
<ul>
<li>节点 A 负责处理 0 号至 5500 号哈希槽。</li>
<li>节点 B 负责处理 5501 号至 11000 号哈希槽。</li>
<li>节点 C 负责处理 11001 号至 16383 号哈希槽。</li>
<li>此时 <code>Redis Client</code> 需要根据一个<code>Key</code>获取对应的 <code>Value</code> 的数据，首先通过 <code>CRC16(key)%16384</code> 计算出 Slot 的值，假设计算的结果是 5000，将这个数据传送给 <code>Redis Cluster</code>，集群接收到以后会到一个对照表中查找这个 <code>Slot=5000</code> 属于那个缓存节点。发现属于“节点 A ”负责，于是顺着红线的方向调用节点 A中存放的 <code>Key-Value</code> 的内容并且返回给 <code>Redis Client</code>。</li>
</ul>
<p>这种将哈希槽分布到不同节点的做法使得用户可以很容易地向集群中添加或者删除节点。 比如说：</p>
<ul>
<li>如果用户将新节点 D 添加到集群中， 那么集群只需要将节点 A 、B 、 C 中的某些槽移动到节点 D 就可以了。</li>
<li>如果用户要从集群中移除节点 A ， 那么集群只需要将节点 A 中的所有哈希槽移动到节点 B 和节点 C ， 然后再移除空白（不包含任何哈希槽）的节点 A 就可以了。</li>
</ul>
<p><strong>因为将一个哈希槽从一个节点移动到另一个节点不会造成节点阻塞，且成本很低， 所以无论是添加新节点还是移除已存在节点， 又或者改变某个节点包含的哈希槽数量， 都不会造成集群下线</strong>。</p>
<h4 id="5-2、数据结构"><a href="#5-2、数据结构" class="headerlink" title="5.2、数据结构"></a>5.2、数据结构</h4><p><code>Redis Cluster</code>中的每个节点都保存了集群的配置信息，并且存储在<code>clusterState</code>中，结构如下：</p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/redis-30.png" alt=""></p>
<p>上图的各个变量语义如下:</p>
<ul>
<li><code>clusterState</code> 记录了从集群中某个节点视角，来看集群配置状态；</li>
<li><code>currentEpoch</code> 表示整个集群中最大的版本号，集群信息每变更一次，改版本号都会自增。</li>
<li><code>nodes</code> 是一个列表，包含了本节点所感知的，集群所有节点的信息（<code>clusterNode</code>），也包含自身的信息。</li>
<li><code>clusterNode</code> 记录了每个节点的信息，其中包含了节点本身的版本 <code>Epoch</code>；自身的信息描述：节点对应的数据分片范围（<code>slot</code>）、为<code>master</code>时的<code>slave</code>列表、为<code>slave</code>时的<code>master</code>等。</li>
</ul>
<p><strong>每个节点包含一个全局唯一的<code>NodeId</code></strong>。</p>
<p>当集群的数据分片信息发生变更（数据在节点间迁移时），<code>Redis Cluster</code>仍然保持对外服务。</p>
<p>当集群中某个master出现宕机时，<code>Redis Cluster</code> 会自动发现，并触发故障转移的操作。会将<code>master</code>的某个<code>slave</code>晋升为新的 <code>master</code>。</p>
<p>由此可见，每个节点都保存着<code>Node</code>视角的集群结构。它描述了数据的分片方式，节点主备关系，并通过<code>Epoch</code>作为版本号实现集群结构信息的一致性，同时也控制着数据迁移和故障转移的过程。</p>
<h4 id="5-3、节点通信"><a href="#5-3、节点通信" class="headerlink" title="5.3、节点通信"></a>5.3、节点通信</h4><p>在<code>Redis Cluster</code>中，这个配置信息交互通过<code>Redis Cluster Bus</code>来完成（<code>独立端口</code>）。<code>Redis Cluster Bus</code>上交互的信息结构如下：</p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/redis-31.png" alt=""></p>
<p><code>clusterMsg</code> 中的<code>type</code>指明了消息的类型，配置信息的一致性主要依靠<code>PING/PONG</code>。每个节点向其他节点频繁的周期性的发送<code>PING/PONG</code>消息。对于消息体中的<code>Gossip</code>部分，包含了<code>sender/receiver</code> 所感知的其他节点信息，接受者根据这些<code>Gossip</code> 跟新对集群的认识。</p>
<p>对于大规模的集群，如果每次<code>PING/PONG</code> 都携带着所有节点的信息，则网络开销会很大。此时<code>Redis Cluster</code> 在每次<code>PING/PONG</code>，只包含了随机的一部分节点信息。由于交互比较频繁，短时间的几次交互之后，集群的状态也会达成一致。</p>
<h4 id="5-4、一致性"><a href="#5-4、一致性" class="headerlink" title="5.4、一致性"></a>5.4、一致性</h4><p>当<code>Cluster</code> 结构不发生变化时，各个节点通过<code>gossip</code> 协议在几轮交互之后，便可以得知<code>Cluster</code>的结构信息，达到一致性的状态。但是当集群结构发生变化时（故障转移/分片迁移等），优先得知变更的节点通过Epoch变量，将自己的最新信息扩散到<code>Cluster</code>，并最终达到一致。</p>
<p><code>clusterNode</code> 的<code>Epoch</code>描述的单个节点的信息版本；<br><code>clusterState</code> 的<code>currentEpoch</code> 描述的是集群信息的版本，它可以辅助<code>Epoch</code> 的自增生成。因为<code>currentEpoch</code> 是维护在每个节点上的，在集群结构发生变更时，<code>Cluster</code> 在一定的时间窗口控制更新规则，来保证每个节点的<code>currentEpoch</code>都是最新的。<br>更新规则如下：</p>
<p>当某个节点率先知道了变更时，将自身的<code>currentEpoch</code> 自增，并使之成为集群中的最大值。再用自增后的<code>currentEpoch</code> 作为新的<code>Epoch</code> 版本；</p>
<ul>
<li>当某个节点收到了比自己大的<code>currentEpoch</code>时，更新自己的<code>currentEpoch</code>；</li>
<li>当收到的<code>Redis Cluster Bus</code> 消息中的某个节点的<code>Epoch</code> &gt; 自身的时，将更新自身的内容；</li>
<li>当<code>Redis Cluster Bus</code> 消息中，包含了自己没有的节点时，将其加入到自身的配置中。</li>
</ul>
<p>上述的规则保证了信息的更新都是单向的，最终朝着<code>Epoch</code>更大的信息收敛。同时<code>Epoch</code>也随着<code>currentEpoch</code>的增加而增加，最终将各节点信息趋于稳定。</p>
<p>为了使得集群在一部分节点下线或者无法与集群的大多数（<code>majority</code>）节点进行通讯的情况下， 仍然可以正常运作， <code>Redis</code> 集群对节点使用了主从复制功能： 集群中的每个节点都有 1 个至 N 个复制品（<code>replica</code>）， 其中一个复制品为主节点（<code>master</code>）， 而其余的 N-1 个复制品为从节点（<code>slave</code>）。</p>
<p><strong>集群间节点支持主从关系</strong>，复制的逻辑基本复用了单机版的实现。不过还是有些地方需要注意。</p>
<ul>
<li>首先集群间节点建立主从关系不再使用原有的<code>SLAVEOF</code>命令和<code>SLAVEOF</code>配置，而是通过<code>cluster replicate</code>命令，这保证了主从节点需要先完成握手，才能建立主从关系。</li>
<li>集群是不能组成链式主从关系的，也就是说从节点不能有自己的从节点。不过对于集群外的没开启集群功能的节点，<code>redis</code>并不干预这些节点去复制集群内的节点，但是在集群故障转移时，这些集群外的节点，集群不会处理。</li>
<li>集群内节点想要复制另一个节点，需要保证本节点不再负责任何<code>slot</code>，不然<code>redis</code>也是不允许的。</li>
<li>集群内的从节点在与其他节点通信的时候，传递的消息中数据分布表和<code>epoch</code>是<code>master</code>的值。</li>
</ul>
<p><strong>集群主节点出现故障，发生故障转移，其他主节点会把故障主节点的从节点自动提为主节点，原来的主节点恢复后，自动成为新主节点的从节点</strong>。</p>
<p>这里先说明，把一个<code>master</code>和它的全部<code>slave</code>描述为一个<code>group</code>，故障转移是以<code>group</code>为单位的，集群故障转移的方式跟sentinel的实现很类似。</p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/redis-32.png" alt=""></p>
<h4 id="5-5、均衡集群"><a href="#5-5、均衡集群" class="headerlink" title="5.5、均衡集群"></a>5.5、均衡集群</h4><p>在集群运行过程中，有的<code>master</code>的<code>slave</code>宕机，导致了该<code>master</code>成为孤儿<code>master</code>（<code>orphaned masters</code>），而有的<code>master</code>有很多<code>slave</code>。</p>
<p>此处孤儿<code>master</code>的定义是那些本来有<code>slave</code>，但是全部离线的<code>master</code>，对于那些原来就没有<code>slave</code>的<code>master</code>不能认为是孤儿<code>master</code>。</p>
<p><code>redis</code>集群支持均衡<code>slave</code>功能，官方称为<code>Replica migration</code>，而我觉得均衡集群的<code>slave</code>更好理解该概念。集群能把某个<code>slave</code>较多的<code>group</code>上的<code>slave</code>迁移到那些孤儿<code>master</code>上，该功能通过<code>cluster-migration-barrier</code>参数配置，默认为1。</p>
<p><code>slave</code>在每次定时任务都会检查是否需要迁移<code>slave</code>，即把自己变成孤儿<code>master</code>的<code>slave</code>。 满足以下条件，<code>slave</code>就会成为孤儿<code>master</code>的<code>slave</code>：</p>
<ul>
<li>自己所在的<code>group</code>是<code>slave</code>最多的<code>group</code>。</li>
<li>目前存在孤儿<code>master</code>。</li>
<li>自己所在的<code>group</code>的<code>slave</code>数目至少超过2个，只有自己一个的话迁移到其他<code>group</code>，自己原来的<code>group</code>的<code>master</code>又成了孤儿<code>master</code>。</li>
<li>自己所在的<code>group</code>的<code>slave</code>数量大于<code>cluster-migration-barrier</code>配置。</li>
<li>与<code>group</code>内的其他<code>slave</code>基于<code>memcmp</code>比较<code>node id</code>，自己的<code>node id</code>最小。这个可以防止多个<code>slave</code>并发复制孤儿<code>master</code>，从而原来的<code>group</code>失去过多的<code>slave</code>。</li>
</ul>
<h5 id="5-5-1、优势"><a href="#5-5-1、优势" class="headerlink" title="5.5.1、优势"></a>5.5.1、优势</h5><ol start="2">
<li>去中心化，集群最大可增加1000个节点，性能随节点增加而线性扩展。</li>
<li>解耦 <strong>数据</strong> 和 <strong>节点</strong> 之间的关系，简化了节点 <strong>扩容</strong> 和 <strong>收缩</strong> 难度。</li>
<li><strong>节点自身</strong> 维护槽的 <strong>映射关系</strong>，不需要 <strong>客户端</strong> 或者 <strong>代理服务</strong> 维护 <strong>槽分区元数据</strong>。</li>
</ol>
<h5 id="5-5-2、劣势"><a href="#5-5-2、劣势" class="headerlink" title="5.5.2、劣势"></a>5.5.2、劣势</h5><ol>
<li><code>key</code> <strong>批量操作</strong> 支持有限。类似 <code>mset</code>、<code>mget</code> 操作，目前只支持对具有相同 <code>slot</code> 值的<code>key</code> 执行 <strong>批量操作</strong>。对于 <strong>映射为不同</strong> <code>slot</code> 值的<code>key</code> 由于执行 <code>mget</code>、<code>mget</code> 等操作可能存在于多个节点上，因此不被支持。</li>
<li>只支持 <strong>多</strong> <code>key</code> 在 <strong>同一节点上</strong> 的 <strong>事务操作</strong>，当多个 <code>key</code> 分布在 <strong>不同</strong> 的节点上时 <strong>无法</strong> 使用事务功能。</li>
<li><code>key</code> 作为 <strong>数据分区</strong> 的最小粒度，不能将一个 <strong>大的键值</strong> 对象如 <code>hash</code>、<code>list</code> 等映射到 <strong>不同的节点</strong>。</li>
<li>不支持<strong>多数据库空间</strong>，<strong>单机</strong>下的<code>Redis</code>可以支持 16 个数据库（db0 ~ db15），<strong>集群模式</strong>下只能使用<strong>一个</strong> 数据库空间，即 db0。</li>
<li><strong>复制结构</strong> 只支持一层，<strong>从节点</strong> 只能复制 <strong>主节点</strong>，不支持 <strong>嵌套树状复制</strong> 结构。</li>
</ol>
<h4 id="5-6、集群搭建"><a href="#5-6、集群搭建" class="headerlink" title="5.6、集群搭建"></a>5.6、集群搭建</h4><h5 id="5-6-1、脚本启动"><a href="#5-6-1、脚本启动" class="headerlink" title="5.6.1、脚本启动"></a>5.6.1、脚本启动</h5><p>​    进入redis源码目录下/utils/create-cluster中执行create-cluster脚本</p>
<p>​    <code>cd /usr/local/redis-6.0.9/utils/create-cluster</code></p>
<h5 id="5-6-2、配置"><a href="#5-6-2、配置" class="headerlink" title="5.6.2、配置"></a>5.6.2、配置</h5><p>​    <code>vim create-cluster</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Settings</span></span><br><span class="line">BIN_PATH=<span class="string">"../../src/"</span></span><br><span class="line">CLUSTER_HOST=127.0.0.1</span><br><span class="line">PORT=30000</span><br><span class="line">TIMEOUT=2000</span><br><span class="line">NODES=6 <span class="comment">#总的节点数量</span></span><br><span class="line">REPLICAS=1 <span class="comment">#每个master对应的slave数量</span></span><br><span class="line">PROTECTED_MODE=yes</span><br><span class="line">ADDITIONAL_OPTIONS=<span class="string">""</span></span><br></pre></td></tr></table></figure>

<p>​        由以上配置可以看出，总节点数为6，每个master对应的slave数量为1，因此根据此配置启动后集群为三主三从模式；后续如果有需要可以修改此配置</p>
<h5 id="5-6-3、启动集群实例"><a href="#5-6-3、启动集群实例" class="headerlink" title="5.6.3、启动集群实例"></a>5.6.3、启动集群实例</h5><p>​    <code>./create-cluster start</code></p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/cluster-%E8%84%9A%E6%9C%AC%E5%90%AF%E5%8A%A8-01.jpg" alt=""></p>
<h5 id="5-6-4、脚本分配slot（hash槽位）"><a href="#5-6-4、脚本分配slot（hash槽位）" class="headerlink" title="5.6.4、脚本分配slot（hash槽位）"></a>5.6.4、脚本分配slot（hash槽位）</h5><p>​     <code>./create-cluster create</code></p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/cluster-%E8%84%9A%E6%9C%AC%E5%90%AF%E5%8A%A8-02.jpg" alt=""></p>
<h5 id="5-6-5、客户端-连接"><a href="#5-6-5、客户端-连接" class="headerlink" title="5.6.5、客户端-连接"></a>5.6.5、客户端-连接</h5><p>客户端在初始化的时候只需要知道一个节点的地址即可，客户端会先尝试向这个节点执行命令，比如<code>“get key”</code>，如果key所在的<code>slot</code>刚好在该节点上，则能够直接执行成功。如果<code>slot</code>不在该节点，则节点会返回MOVED错误，同时把该slot对应的节点告诉客户端。客户端可以去该节点执行命令。</p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/redis-29.png" alt=""></p>
<h6 id="普通客户端模式-连接"><a href="#普通客户端模式-连接" class="headerlink" title="普通客户端模式-连接"></a>普通客户端模式-连接</h6><p>​    <code>redis-cli -p 30001</code></p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/cluster-%E6%99%AE%E9%80%9A%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%A8%A1%E5%BC%8F%E8%BF%9E%E6%8E%A5-01.jpg" alt=""></p>
<p>​    key分配的slot不在当前连接的redis server时，服务端返回错误提示，让客户端自己进行跳转 <code>(error) MOVED 12706 127.0.0.1:30003</code></p>
<h6 id="集群客户端模式-连接"><a href="#集群客户端模式-连接" class="headerlink" title="集群客户端模式-连接"></a>集群客户端模式-连接</h6><p>​    <code>redis-cli -c -p 30001</code></p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/cluster-%E9%9B%86%E7%BE%A4%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%A8%A1%E5%BC%8F%E8%BF%9E%E6%8E%A5.jpg" alt=""></p>
<p>​    key分配的slot不在当前连接的redis server时，集群模式客户端会帮助我们进行重定向跳转 <code>Redirected to slot [12706] located at 127.0.0.1:30003</code></p>
<h5 id="5-6-6、注意"><a href="#5-6-6、注意" class="headerlink" title="5.6.6、注意"></a>5.6.6、注意</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">	不管是&#96;普通客户端模式&#96;还是&#96;集群客户端模式&#96;去连接服务，如果key不在一个slot仍无法使用事务等指令</span><br><span class="line">​	解决同类业务数据不在同个 redis哈希槽的问题，在key上加上&#123;tag&#125;来标识某个key，会计算第一次出现&#39;&#123;&#39;到第一次出现&#39;&#125;&#39;之间的subString内容的hash值，如果该内容为空，则计算整个key;这种方式是解决分区key不同分区的通用解决方案</span><br></pre></td></tr></table></figure>

<h5 id="5-6-7、停止实例"><a href="#5-6-7、停止实例" class="headerlink" title="5.6.7、停止实例"></a>5.6.7、停止实例</h5><p>​    停止所有正在运行的redis-cluster实例 <code>./create-cluster stop</code></p>
<h5 id="5-6-7、还原实例"><a href="#5-6-7、还原实例" class="headerlink" title="5.6.7、还原实例"></a>5.6.7、还原实例</h5><p>​    清除配置、日志、持久化文件 <code>./create-cluster clean</code></p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/cluster-%E6%B8%85%E9%99%A4%E9%85%8D%E7%BD%AE%E8%BF%98%E5%8E%9F.jpg" alt=""></p>
<h5 id="5-6-8、手动启动"><a href="#5-6-8、手动启动" class="headerlink" title="5.6.8、手动启动"></a>5.6.8、手动启动</h5><p>修改redis配置，之后启动redis时加载此配置 <code>redis-server ./6379.conf</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">################################ REDIS CLUSTER  ###############################</span></span><br><span class="line"><span class="comment">#redis.conf相关集群配置</span></span><br><span class="line"><span class="comment">#配置为cluster模式</span></span><br><span class="line">cluster-enabled yes</span><br><span class="line"></span><br><span class="line"><span class="comment">#集群节点配置信息，包括nodeid，集群信息。此文件非常关键，要确保故障转移或者重启的时候此文件还在，所以如果在docker环境下要外挂到外部存储</span></span><br><span class="line">cluster-config-file nodes-6379.conf</span><br><span class="line"></span><br><span class="line"><span class="comment">#节点连接超时，如果集群规模小，都在同一个网络环境下，可以配置的短些，更快的做故障转移</span></span><br><span class="line">cluster-node-timeout 2000</span><br><span class="line"></span><br><span class="line"><span class="comment">#慢查询日志，用于性能分析，生产环境可设置为1000（毫秒）</span></span><br><span class="line">slowlog-log-slower-than 1000</span><br><span class="line"></span><br><span class="line"><span class="comment">#保存慢查询的队列长度 ，设置为1000</span></span><br><span class="line">slowlog-max-len 1000</span><br><span class="line"></span><br><span class="line"><span class="comment">#设置为0，默认为10如果master slave都挂掉，slave跟master失联又超过这个数值*timeout的数值，就不会发起选举了。</span></span><br><span class="line"><span class="comment">#如果设置为0，就是永远都会尝试发起选举，尝试从slave变为mater</span></span><br><span class="line">cluster-slave-validity-factor 10</span><br><span class="line"></span><br><span class="line"><span class="comment">#设置为no，默认为yes，故障发现到自动完成转移期间整个集群是不可用状态，对于大多数业务无法容忍这种情况</span></span><br><span class="line"><span class="comment">#因此要设置为no，当主节点故障时只影 响它负责槽的相关命令执行，不会影响其他主节点的可用性</span></span><br><span class="line">cluster-require-full-coverage yes</span><br></pre></td></tr></table></figure>



<h5 id="5-6-9、手动分配slot（hash槽）"><a href="#5-6-9、手动分配slot（hash槽）" class="headerlink" title="5.6.9、手动分配slot（hash槽）"></a>5.6.9、手动分配slot（hash槽）</h5><p>​    使用此方式可以自己指定参与集群的redis节点，设置slave节点数，适合真实环境下多服务器实例的集群搭建</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli --cluster create 127.0.0.1:30001 127.0.0.1:30002 127.0.0.1:30003 127.0.0.1:30004 127.0.0.1:30005 127.0.0.1:30006 --cluster-replicas 1</span><br></pre></td></tr></table></figure>

<h5 id="5-6-10、移动slot"><a href="#5-6-10、移动slot" class="headerlink" title="5.6.10、移动slot"></a>5.6.10、移动slot</h5><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#实行重新分片命令，可任意连接一个redis实例进行操作</span></span><br><span class="line">redis-cli --cluster reshard 127.0.0.1:30001</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:30001)</span><br><span class="line">M: 1ba79d08eacd99fa3791d1824907a3e3e136cf06 127.0.0.1:30001</span><br><span class="line">   slots:[0-5460] (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: d23ba04b97a59fa4bf3400510feb128ef0694520 127.0.0.1:30004</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 1ba79d08eacd99fa3791d1824907a3e3e136cf06</span><br><span class="line">S: 40b2868d28ac09031df1caa9847066eadebfa4f7 127.0.0.1:30006</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates e5bb13b4ea84f4fd5f23a944ae59a6768a34be28</span><br><span class="line">S: ddeb75d4235f26ce86fe30d3aa9edffde92d5a31 127.0.0.1:30005</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates e3e285582cabc5360d74e99c778867526cecb2a1</span><br><span class="line">M: e3e285582cabc5360d74e99c778867526cecb2a1 127.0.0.1:30002</span><br><span class="line">   slots:[5461-10922] (5462 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: e5bb13b4ea84f4fd5f23a944ae59a6768a34be28 127.0.0.1:30003</span><br><span class="line">   slots:[10923-16383] (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check <span class="keyword">for</span> open slots...</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br><span class="line"><span class="comment">#想要移动多少槽位？这里指定了2000</span></span><br><span class="line">How many slots <span class="keyword">do</span> you want to move (from 1 to 16384)? 2000</span><br><span class="line"><span class="comment"># 想要移动到哪个节点？这里指定了30002的节点id</span></span><br><span class="line">What is the receiving node ID? e3e285582cabc5360d74e99c778867526cecb2a1</span><br><span class="line">Please enter all the <span class="built_in">source</span> node IDs.</span><br><span class="line">  Type <span class="string">'all'</span> to use all the nodes as <span class="built_in">source</span> nodes <span class="keyword">for</span> the <span class="built_in">hash</span> slots.</span><br><span class="line">  Type <span class="string">'done'</span> once you entered all the <span class="built_in">source</span> nodes IDs.</span><br><span class="line">Source node <span class="comment">#1: 1ba79d08eacd99fa3791d1824907a3e3e136cf06</span></span><br><span class="line">Source node <span class="comment">#2: done</span></span><br><span class="line"><span class="comment">#略</span></span><br><span class="line">    Moving slot 1998 from 1ba79d08eacd99fa3791d1824907a3e3e136cf06</span><br><span class="line">    Moving slot 1999 from 1ba79d08eacd99fa3791d1824907a3e3e136cf06</span><br><span class="line"><span class="comment"># 是否执行表重新分片计划？yes</span></span><br><span class="line">Do you want to proceed with the proposed reshard plan (yes/no)? yes</span><br><span class="line"><span class="comment">#略</span></span><br><span class="line">Moving slot 1997 from 127.0.0.1:30001 to 127.0.0.1:30002: </span><br><span class="line">Moving slot 1998 from 127.0.0.1:30001 to 127.0.0.1:30002: </span><br><span class="line">Moving slot 1999 from 127.0.0.1:30001 to 127.0.0.1:30002:</span><br></pre></td></tr></table></figure>

<p>如下图所示，有2000个槽位从30001的实例迁移到了30002的实例中</p>
<p><img src="http://yrlzero.gitee.io/images/linux/redis/cluster-%E7%A7%BB%E5%8A%A8%E6%A7%BD%E4%BD%8D-02.jpg" alt=""></p>
<h5 id="5-6-11、集群客户端-帮助"><a href="#5-6-11、集群客户端-帮助" class="headerlink" title="5.6.11、集群客户端-帮助"></a>5.6.11、集群客户端-帮助</h5><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">[root@centos-3 create-cluster]<span class="comment"># redis-cli --cluster help</span></span><br><span class="line">Cluster Manager Commands:</span><br><span class="line">  create         host1:port1 ... hostN:portN</span><br><span class="line">                 --cluster-replicas &lt;arg&gt;</span><br><span class="line">  check          host:port</span><br><span class="line">                 --cluster-search-multiple-owners</span><br><span class="line">  info           host:port</span><br><span class="line">  fix            host:port</span><br><span class="line">                 --cluster-search-multiple-owners</span><br><span class="line">                 --cluster-fix-with-unreachable-masters</span><br><span class="line">  reshard        host:port</span><br><span class="line">                 --cluster-from &lt;arg&gt;</span><br><span class="line">                 --cluster-to &lt;arg&gt;</span><br><span class="line">                 --cluster-slots &lt;arg&gt;</span><br><span class="line">                 --cluster-yes</span><br><span class="line">                 --cluster-timeout &lt;arg&gt;</span><br><span class="line">                 --cluster-pipeline &lt;arg&gt;</span><br><span class="line">                 --cluster-replace</span><br><span class="line">  rebalance      host:port</span><br><span class="line">                 --cluster-weight &lt;node1=w1...nodeN=wN&gt;</span><br><span class="line">                 --cluster-use-empty-masters</span><br><span class="line">                 --cluster-timeout &lt;arg&gt;</span><br><span class="line">                 --cluster-simulate</span><br><span class="line">                 --cluster-pipeline &lt;arg&gt;</span><br><span class="line">                 --cluster-threshold &lt;arg&gt;</span><br><span class="line">                 --cluster-replace</span><br><span class="line">  add-node       new_host:new_port existing_host:existing_port</span><br><span class="line">                 --cluster-slave</span><br><span class="line">                 --cluster-master-id &lt;arg&gt;</span><br><span class="line">  del-node       host:port node_id</span><br><span class="line">  call           host:port <span class="built_in">command</span> arg arg .. arg</span><br><span class="line">                 --cluster-only-masters</span><br><span class="line">                 --cluster-only-replicas</span><br><span class="line">  <span class="built_in">set</span>-timeout    host:port milliseconds</span><br><span class="line">  import         host:port</span><br><span class="line">                 --cluster-from &lt;arg&gt;</span><br><span class="line">                 --cluster-copy</span><br><span class="line">                 --cluster-replace</span><br><span class="line">  backup         host:port backup_directory</span><br><span class="line">  <span class="built_in">help</span>           </span><br><span class="line"></span><br><span class="line">For check, fix, reshard, del-node, <span class="built_in">set</span>-timeout you can specify the host and port of any working node <span class="keyword">in</span> the cluster.</span><br></pre></td></tr></table></figure>


    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/db/" rel="tag"># db</a>
              <a href="/tags/redis/" rel="tag"># redis</a>
              <a href="/tags/nosql/" rel="tag"># nosql</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/04/11/redis%E6%8C%81%E4%B9%85%E5%8C%96/" rel="prev" title="redis-持久化">
      <i class="fa fa-chevron-left"></i> redis-持久化
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/04/17/redis%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/" rel="next" title="redis-常见问题">
      redis-常见问题 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#一、主从复制"><span class="nav-text">一、主从复制</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1、概念"><span class="nav-text">1、概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2、复制原理"><span class="nav-text">2、复制原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3、准备"><span class="nav-text">3、准备</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4、启动redis"><span class="nav-text">4、启动redis</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5、slave追随master"><span class="nav-text">5、slave追随master</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6、错误"><span class="nav-text">6、错误</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#6-1、问题1："><span class="nav-text">6.1、问题1：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2、问题2："><span class="nav-text">6.2、问题2：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-3、问题3："><span class="nav-text">6.3、问题3：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-4、问题4："><span class="nav-text">6.4、问题4：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7、slave升级为master"><span class="nav-text">7、slave升级为master</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8、配置"><span class="nav-text">8、配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9、总结"><span class="nav-text">9、总结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#二、哨兵模式"><span class="nav-text">二、哨兵模式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1、概念-1"><span class="nav-text">1、概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2、Sentinel相互发现"><span class="nav-text">2、Sentinel相互发现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3、Sentinel对master的故障判定"><span class="nav-text">3、Sentinel对master的故障判定</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4、选举新的master"><span class="nav-text">4、选举新的master</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5、准备"><span class="nav-text">5、准备</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6、配置"><span class="nav-text">6、配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7、启动哨兵节点"><span class="nav-text">7、启动哨兵节点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8、选举新master节点"><span class="nav-text">8、选举新master节点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#总结"><span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#三、分区"><span class="nav-text">三、分区</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1、概念-2"><span class="nav-text">1、概念</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1、不同端的分区"><span class="nav-text">1.1、不同端的分区</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2、优缺点"><span class="nav-text">1.2、优缺点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-3、预分片"><span class="nav-text">1.3、预分片</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2、分区算法"><span class="nav-text">2、分区算法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1、普通Hash算法（modula）"><span class="nav-text">2.1、普通Hash算法（modula）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2、随机分配算法-random"><span class="nav-text">2.2、随机分配算法(random)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3、一致性Hash算法-ketama"><span class="nav-text">2.3、一致性Hash算法(ketama)</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#容错性和可扩展性"><span class="nav-text">容错性和可扩展性</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#虚拟节点"><span class="nav-text">虚拟节点</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#实现"><span class="nav-text">实现</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-4、哈希槽"><span class="nav-text">2.4、哈希槽</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3、代理分区-TwemProxy"><span class="nav-text">3、代理分区-TwemProxy</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1、安装"><span class="nav-text">3.1、安装</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2、配置"><span class="nav-text">3.2、配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3、手动启动redis"><span class="nav-text">3.3、手动启动redis</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-4、启动twemproxy"><span class="nav-text">3.4、启动twemproxy</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-5、通过代理连接redis"><span class="nav-text">3.5、通过代理连接redis</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4、代理分区-Predixy"><span class="nav-text">4、代理分区-Predixy</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1、安装"><span class="nav-text">4.1、安装</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2、predixy相关配置"><span class="nav-text">4.2、predixy相关配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3、sentinel配置"><span class="nav-text">4.3、sentinel配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-4、启动sentinel"><span class="nav-text">4.4、启动sentinel</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-5、启动redis主从"><span class="nav-text">4.5、启动redis主从</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-6、启动predixy"><span class="nav-text">4.6、启动predixy</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-7、通过代理连接redis"><span class="nav-text">4.7、通过代理连接redis</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5、查询路由分区-Redis-Cluster"><span class="nav-text">5、查询路由分区-Redis-Cluster</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#5-1、slot分配"><span class="nav-text">5.1、slot分配</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-2、数据结构"><span class="nav-text">5.2、数据结构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-3、节点通信"><span class="nav-text">5.3、节点通信</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-4、一致性"><span class="nav-text">5.4、一致性</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-5、均衡集群"><span class="nav-text">5.5、均衡集群</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#5-5-1、优势"><span class="nav-text">5.5.1、优势</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-5-2、劣势"><span class="nav-text">5.5.2、劣势</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-6、集群搭建"><span class="nav-text">5.6、集群搭建</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#5-6-1、脚本启动"><span class="nav-text">5.6.1、脚本启动</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-6-2、配置"><span class="nav-text">5.6.2、配置</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-6-3、启动集群实例"><span class="nav-text">5.6.3、启动集群实例</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-6-4、脚本分配slot（hash槽位）"><span class="nav-text">5.6.4、脚本分配slot（hash槽位）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-6-5、客户端-连接"><span class="nav-text">5.6.5、客户端-连接</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#普通客户端模式-连接"><span class="nav-text">普通客户端模式-连接</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#集群客户端模式-连接"><span class="nav-text">集群客户端模式-连接</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-6-6、注意"><span class="nav-text">5.6.6、注意</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-6-7、停止实例"><span class="nav-text">5.6.7、停止实例</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-6-7、还原实例"><span class="nav-text">5.6.7、还原实例</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-6-8、手动启动"><span class="nav-text">5.6.8、手动启动</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-6-9、手动分配slot（hash槽）"><span class="nav-text">5.6.9、手动分配slot（hash槽）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-6-10、移动slot"><span class="nav-text">5.6.10、移动slot</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-6-11、集群客户端-帮助"><span class="nav-text">5.6.11、集群客户端-帮助</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="yrl"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">yrl</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">53</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">20</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">35</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">yrl</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  
</body>
</html>
